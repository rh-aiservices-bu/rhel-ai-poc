judge:
  endpoint_url: None #TODO: currently uses OpenAI API endpoint
  model_name: gpt-4
  api_key: <OPENAI_API_KEY>
  template: |
    You are an evaluation system tasked with assessing the answer quality of a AI generated response in relation to the posed question and reference answer. Assess if the response is correct, accurate, and factual based on the reference answer. Evaluate the answer_quality as:
    - Score 1: The response is completely incorrect, inaccurate, and/or not factual.
    - Score 2: The response is mostly incorrect, inaccurate, and/or not factual.
    - Score 3: The response is somewhat correct, accurate, and/or factual.
    - Score 4: The response is mostly correct, accurate, and factual.
    - Score 5: The response is completely correct, accurate, and factual.
    Here is the question: \n ------- \n {question} \n -------
    Here is model answer: \n ------- \n {answer} \n -------
    Here is the reference answer(may be very short and lack details or indirect, long and extractive):  \n ------- \n {reference_answer} \n ------- \n
    Assess the quality of model answer with respect to the Reference Answer, but do not penalize the model answer for adding details or give a direct answer to user question. Provide the quality level as a JSON object with two keys: 'reasoning' and 'answer_quality'.
testing_config:
  - name: analyst-day
    endpoint_url: <INFERENCE_URL> #https://model.server.com/v1
    model_name: <MODEL_NAME> #granite
    api_key: <LLM_API_KEY>
    qna_template: |
      <|system|>
      You are a Red Hat Instruct Model based on Granite 7B,
      an AI language model developed by Red Hat and IBM Research,
      based on the Granite-7b-base language model.
      Your primary function is to be a chat assistant.
      <|user|>
      Answer the following question.
      Question: {question}
      Answer:
      <|assistant|>
    rag_template: |
      <|system|>
      You are a Red Hat Instruct Model based on Granite 7B,
      an AI language model developed by Red Hat and IBM Research,
      based on the Granite-7b-base language model.
      Your primary function is to be a chat assistant.
      <|user|>
      Context:
      {context}
      Answer the following question from context and internal memory.
      Question: {question}
      Answer:
      <|assistant|>
