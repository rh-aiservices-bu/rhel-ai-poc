name: gpt-4-eval
judge:
  endpoint_url: '' # defaults to OpenAI API endpoint
  model_name: gpt-4
  api_key: <API_KEY>
  template: |
    You are an evaluation system tasked with assessing the answer quality of a AI generated response in relation to the posed question and reference answer. Assess if the response is correct, accurate, and factual based on the reference answer.
    For evaluating factuality of the answer look at the reference answer compare the model answer to it.
    Evaluate the answer_quality as:
    - Score 1: The response is completely incorrect, inaccurate, and/or not factual.
    - Score 2: The response is mostly incorrect, inaccurate, and/or not factual.
    - Score 3: The response is somewhat correct, accurate, and/or factual.
    - Score 4: The response is mostly correct, accurate, and factual.
    - Score 5: The response is completely correct, accurate, and factual.
    Here is the question: \n ------- \n {question} \n -------
    Here is model answer: \n ------- \n {answer} \n -------
    Here is the reference answer(may be very short and lack details or indirect, long and extractive):  \n ------- \n {reference_answer} \n ------- \n
    Assess the quality of model answer with respect to the Reference Answer, but do not penalize the model answer for adding details or give a direct answer to user question.
    Approach your evaluation in step-by-step manner.
    For evaluating first list out keys facts covered in the reference answer and check how many are covered by the model answer.
    If the question or reference answer is about steps then check if the steps and their order in model answer match with reference answer.
    Provide your response as JSON object with two keys: 'reasoning' and 'answer_quality'.
testing_config:
  - name: finetuned
    endpoint_url: <ENDPOINT_URL>
    model_name: finetuned
    api_key: <API_KEY>
    qna_template: |
      <|system|>
      You are a Red Hat Instruct Model based on Granite 7B,
      an AI language model developed by Red Hat and IBM Research,
      based on the Granite-7b-base language model.
      Your primary function is to be a chat assistant.
      <|user|>
      Answer the following question.
      Question: {question}
      Answer:
      <|assistant|>
    rag_template: |
      <|system|>
      You are a Red Hat Instruct Model based on Granite 7B,
      an AI language model developed by Red Hat and IBM Research,
      based on the Granite-7b-base language model.
      Your primary function is to be a chat assistant.
      <|user|>
      Context:
      {context}
      Answer the following question from context and internal memory.
      Question: {question}
      Answer:
      <|assistant|>
  - name: granite-7b
    endpoint_url: <ENDPOINT_URL>
    model_name: granite-7b
    api_key: <API_KEY>
    rag_template: |
      <|system|>
      You are Granite 7B, an AI language model developed by Red Hat and IBM Research.
      Your primary function is to be a chat assistant.
      <|user|>
      Context:
      {context}
      Answer the following question from context.
      Question: {question}
      Answer:
      <|assistant|>
  - name: gpt-4
    model_name: gpt-4
    model_type: openai
    api_key: <API_KEY>
    rag_template: |
      <|user|>
      Context:
      {context}
      Answer the following question from context.
      Question: {question}
      Answer:
      <|assistant|>